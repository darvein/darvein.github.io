<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta http-equiv=Content-Security-Policy content="upgrade-insecure-requests; block-all-mixed-content; default-src 'self' https://www.dropbox.com https://*.dl.dropboxusercontent.com https://photos.app.goo.gl https://drive.google.com https://photos.google.com https://video-downloads.googleusercontent.com https://*.googleusercontent.com https://*.googlevideo.com https://youtube.googleapis.com; child-src 'self'; font-src 'self' https://fonts.gstatic.com https://cdn.jsdelivr.net/; form-action 'self'; frame-src 'self' https://w.soundcloud.com https://www.youtube.com https://www.youtube-nocookie.com https://www.dropbox.com http://localhost https://www.dropbox.com http://darvein.local https://disqus.com; img-src 'self' https://photos.google.com https://lh3.googleusercontent.com https://www.dropbox.com https://*.dl.dropboxusercontent.com https://*.disqus.com https://c.disquscdn.com; object-src https://lh3.googleusercontent.com; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com/ https://cdn.jsdelivr.net/ https://c.disquscdn.com; script-src 'self' 'unsafe-inline' https://www.google-analytics.com https://cdnjs.cloudflare.com https://www.googletagmanager.com https://www.dropbox.com http://localhost http://darvein.local https://drv21.disqus.com https://c.disquscdn.com; prefetch-src 'self' https://youtube.googleapis.com; connect-src 'self' https://www.google-analytics.com https://links.services.disqus.com;"><meta name=author content="Dennis Ruiz"><meta name=description content="Quickstart Setup the model We basically start getting the training and test data from FashionMNIST which is one of the many available vision datasets for pytorch.
(dev) ~z➤ python 01.py Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) Shape of y: torch.Size([64]) torch.int64 Then we create the model. Here we basically we use a lot nn.Module lib, it helps creating the NeuralNetwork and other parameters for itself."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Quickstart Setup the model We basically start getting the training and test data from FashionMNIST which is one of the many available vision datasets for pytorch.
(dev) ~z➤ python 01.py Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) Shape of y: torch.Size([64]) torch.int64 Then we create the model. Here we basically we use a lot nn.Module lib, it helps creating the NeuralNetwork and other parameters for itself."><meta property="og:title" content><meta property="og:description" content="Quickstart Setup the model We basically start getting the training and test data from FashionMNIST which is one of the many available vision datasets for pytorch.
(dev) ~z➤ python 01.py Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) Shape of y: torch.Size([64]) torch.int64 Then we create the model. Here we basically we use a lot nn.Module lib, it helps creating the NeuralNetwork and other parameters for itself."><meta property="og:type" content="article"><meta property="og:url" content="https://www.darvein.net/coding/pytorch/pytorch-tutorials/01-quickstart/"><meta property="article:section" content="coding"><title>Quickstart </title><link rel=canonical href=https://www.darvein.net/coding/pytorch/pytorch-tutorials/01-quickstart/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.a1a7e7e7bd8b6629931805334fd6cf056ee6f154702847e6d597bbfe80446a0d.css integrity="sha256-oafn572LZimTGAUzT9bPBW7m8VRwKEfm1Ze7/oBEag0=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css integrity="sha256-OeQafxa9+MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/custom.min.7cf8a329bb485491ed5be45bd286916c655bf66e11e3fe4d82649437eae8b51b.css integrity="sha256-fPijKbtIVJHtW+Rb0oaRbGVb9m4R4/5NgmSUN+rotRs=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.120.4"></head><body class="preload-transitions colorscheme-dark"><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Darvein
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/infosec/>Infosec</a></li><li class=navigation-item><a class=navigation-link href=/coding/>Coding</a></li><li class=navigation-item><a class=navigation-link href=/devops/>Devops</a></li></ul></section></nav><div class=content><section class="container page"><article><h1 id=quickstart>Quickstart
<a class=heading-link href=#quickstart><i class="fa fa-link" aria-hidden=true></i></a></h1><h2 id=setup-the-model>Setup the model
<a class=heading-link href=#setup-the-model><i class="fa fa-link" aria-hidden=true></i></a></h2><p>We basically start getting the training and test data from <strong>FashionMNIST</strong> which is one of the many available vision datasets for pytorch.</p><div class=highlight><pre tabindex=0 style=color:#fff;background-color:#111;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-bash data-lang=bash><span style=display:flex><span>(dev) ~z➤ python 01.py
</span></span><span style=display:flex><span>Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])
</span></span><span style=display:flex><span>Shape of y: torch.Size([64]) torch.int64
</span></span></code></pre></div><p>Then we create the model.
Here we basically we use a lot <code>nn.Module</code> lib, it helps creating the NeuralNetwork and other parameters for itself. We are also using <code>cuda</code> (bcoz I have NVIDIA like the pros &#x1f480;) where the model will be processed.
(dev) ~z➤ python 01.py</p><div class=highlight><pre tabindex=0 style=color:#fff;background-color:#111;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-bash data-lang=bash><span style=display:flex><span>Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])
</span></span><span style=display:flex><span>Shape of y: torch.Size([64]) torch.int64
</span></span><span style=display:flex><span>(dev) ~z➤ python 01.py
</span></span><span style=display:flex><span>Using cuda device
</span></span><span style=display:flex><span>NeuralNetwork(
</span></span><span style=display:flex><span>  (flatten): Flatten(<span style=color:#fb660a>start_dim</span>=1, <span style=color:#fb660a>end_dim</span>=-1)
</span></span><span style=display:flex><span>  (linear_relu_stack): Sequential(
</span></span><span style=display:flex><span>    (0): Linear(<span style=color:#fb660a>in_features</span>=784, <span style=color:#fb660a>out_features</span>=512, <span style=color:#fb660a>bias</span>=True)
</span></span><span style=display:flex><span>    (1): ReLU()
</span></span><span style=display:flex><span>    (2): Linear(<span style=color:#fb660a>in_features</span>=512, <span style=color:#fb660a>out_features</span>=512, <span style=color:#fb660a>bias</span>=True)
</span></span><span style=display:flex><span>    (3): ReLU()
</span></span><span style=display:flex><span>    (4): Linear(<span style=color:#fb660a>in_features</span>=512, <span style=color:#fb660a>out_features</span>=10, <span style=color:#fb660a>bias</span>=True)
</span></span><span style=display:flex><span>  )
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h2 id=train-and-test>Train and Test
<a class=heading-link href=#train-and-test><i class="fa fa-link" aria-hidden=true></i></a></h2><p>With use of Loss Function and Optimizer we can train the model so it can make predictions and propagate results back in order to tune better the model&rsquo;s params.
We should also <strong>test</strong> the model to evaluate wether its learning or not.</p><p>The loss function gets the info on how well the model performed and the optimizer tunes the model to make it better the next time.</p><p>After training and testing the model during various epochs:</p><div class=highlight><pre tabindex=0 style=color:#fff;background-color:#111;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-bash data-lang=bash><span style=display:flex><span>...
</span></span><span style=display:flex><span>loss: 0.833402  [57664/60000]
</span></span><span style=display:flex><span>Test Error:
</span></span><span style=display:flex><span> Accuracy: 70.0%, Avg loss: 0.819294
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Epoch <span style=color:#0086f7;font-weight:700>10</span>
</span></span><span style=display:flex><span>-------------------------------
</span></span><span style=display:flex><span>loss: 0.833612  [   64/60000]
</span></span><span style=display:flex><span>loss: 0.903723  [ 6464/60000]
</span></span><span style=display:flex><span>loss: 0.679648  [12864/60000]
</span></span><span style=display:flex><span>loss: 0.873493  [19264/60000]
</span></span><span style=display:flex><span>loss: 0.766314  [25664/60000]
</span></span><span style=display:flex><span>loss: 0.765345  [32064/60000]
</span></span><span style=display:flex><span>loss: 0.839947  [38464/60000]
</span></span><span style=display:flex><span>loss: 0.817787  [44864/60000]
</span></span><span style=display:flex><span>loss: 0.811614  [51264/60000]
</span></span><span style=display:flex><span>loss: 0.804626  [57664/60000]
</span></span><span style=display:flex><span>Test Error:
</span></span><span style=display:flex><span> Accuracy: 71.2%, Avg loss: 0.787830
</span></span></code></pre></div><h2 id=saving-loading-and-testing-the-model>Saving, Loading and Testing the model
<a class=heading-link href=#saving-loading-and-testing-the-model><i class="fa fa-link" aria-hidden=true></i></a></h2><p>After training and validating the model, we can now save and load and manually test the model.</p><div class=highlight><pre tabindex=0 style=color:#fff;background-color:#111;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-bash data-lang=bash><span style=display:flex><span>Done!
</span></span><span style=display:flex><span>Predicted: <span style=color:#0086d2>&#34;Ankle boot&#34;</span>, Actual: <span style=color:#0086d2>&#34;Ankle boot&#34;</span>
</span></span></code></pre></div><p>Check all of this examples in the file: &#x1f517;
<a href=../labs/01.py>labs/01.py</a></p></article></section></div><footer class=footer><section class=container>©
2021 -
2024
Dennis Ruiz
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js integrity="sha256-I2BJOV3DaC+ycZZAhylY4S8fJAZ7sJwyeyM+YpDH7aw="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6CQZY8W0WD"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6CQZY8W0WD")</script><script>$(document).on("input propertychange paste change",".FilterSearch",function(){var n=$(this).val().toLowerCase(),s=$(this).closest("ul"),t=s.find("li:gt(0)");t.hide(),t.filter(function(){var e=$(this).text().toLowerCase();return e.indexOf(n)>=0}).show()})</script></body></html>