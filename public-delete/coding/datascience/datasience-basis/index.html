<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta http-equiv=Content-Security-Policy content="upgrade-insecure-requests; block-all-mixed-content; default-src 'self' https://www.dropbox.com https://*.dl.dropboxusercontent.com https://photos.app.goo.gl https://drive.google.com https://photos.google.com https://video-downloads.googleusercontent.com https://*.googleusercontent.com https://*.googlevideo.com https://youtube.googleapis.com; child-src 'self'; font-src 'self' https://fonts.gstatic.com https://cdn.jsdelivr.net/; form-action 'self'; frame-src 'self' https://w.soundcloud.com https://www.youtube.com https://www.youtube-nocookie.com https://www.dropbox.com http://localhost https://www.dropbox.com http://darvein.local https://disqus.com; img-src 'self' https://photos.google.com https://lh3.googleusercontent.com https://www.dropbox.com https://*.dl.dropboxusercontent.com https://*.disqus.com https://c.disquscdn.com; object-src https://lh3.googleusercontent.com; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com/ https://cdn.jsdelivr.net/ https://c.disquscdn.com; script-src 'self' 'unsafe-inline' https://www.google-analytics.com https://cdnjs.cloudflare.com https://www.googletagmanager.com https://www.dropbox.com http://localhost http://darvein.local https://drv21.disqus.com https://c.disquscdn.com; prefetch-src 'self' https://youtube.googleapis.com; connect-src 'self' https://www.google-analytics.com https://links.services.disqus.com;"><meta name=author content="Dennis Ruiz"><meta name=description content="Datascience basis Intro Data VS Big Data!!! &mdash;> Se trata de las mismas ideas y objetivos aplicadas a 2 situaciones:
cuando el volumen, la velocidad, la variedad, la veracidad/confiabilidad, y el valor del corpus de datos en uso son manejables dentro de los parámetros básicos en cuanto a infraestructura lógica y técnicas de procesamiento cuando el volumen, la velocidad, la variedad, la veracidad/confiabilidad, y el valor del corpus de datos en uso son tales (en un caso o en los cinco) que hacen necesario el despliegue, operaciones y procesamiento en un ecosistema distribuido Steps: En la práctica estos pasos no son lineales e incrementales, sino q pueden ser iterativos o simultáneos &mldr;como puede verse, los pasos 1 y 2 corresponden a lo q normalmente se entiende como Data Engineering, en tanto q los pasos 3 al 6 son más bien lo q corresponde al Data Scientist como tal."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Datascience basis Intro Data VS Big Data!!! &mdash;> Se trata de las mismas ideas y objetivos aplicadas a 2 situaciones:
cuando el volumen, la velocidad, la variedad, la veracidad/confiabilidad, y el valor del corpus de datos en uso son manejables dentro de los parámetros básicos en cuanto a infraestructura lógica y técnicas de procesamiento cuando el volumen, la velocidad, la variedad, la veracidad/confiabilidad, y el valor del corpus de datos en uso son tales (en un caso o en los cinco) que hacen necesario el despliegue, operaciones y procesamiento en un ecosistema distribuido Steps: En la práctica estos pasos no son lineales e incrementales, sino q pueden ser iterativos o simultáneos &mldr;como puede verse, los pasos 1 y 2 corresponden a lo q normalmente se entiende como Data Engineering, en tanto q los pasos 3 al 6 son más bien lo q corresponde al Data Scientist como tal."><meta property="og:title" content><meta property="og:description" content="Datascience basis Intro Data VS Big Data!!! &mdash;> Se trata de las mismas ideas y objetivos aplicadas a 2 situaciones:
cuando el volumen, la velocidad, la variedad, la veracidad/confiabilidad, y el valor del corpus de datos en uso son manejables dentro de los parámetros básicos en cuanto a infraestructura lógica y técnicas de procesamiento cuando el volumen, la velocidad, la variedad, la veracidad/confiabilidad, y el valor del corpus de datos en uso son tales (en un caso o en los cinco) que hacen necesario el despliegue, operaciones y procesamiento en un ecosistema distribuido Steps: En la práctica estos pasos no son lineales e incrementales, sino q pueden ser iterativos o simultáneos &mldr;como puede verse, los pasos 1 y 2 corresponden a lo q normalmente se entiende como Data Engineering, en tanto q los pasos 3 al 6 son más bien lo q corresponde al Data Scientist como tal."><meta property="og:type" content="article"><meta property="og:url" content="https://www.darvein.net/coding/datascience/datasience-basis/"><meta property="article:section" content="coding"><title>Datascience basis </title><link rel=canonical href=https://www.darvein.net/coding/datascience/datasience-basis/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.a1a7e7e7bd8b6629931805334fd6cf056ee6f154702847e6d597bbfe80446a0d.css integrity="sha256-oafn572LZimTGAUzT9bPBW7m8VRwKEfm1Ze7/oBEag0=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css integrity="sha256-OeQafxa9+MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/custom.min.7cf8a329bb485491ed5be45bd286916c655bf66e11e3fe4d82649437eae8b51b.css integrity="sha256-fPijKbtIVJHtW+Rb0oaRbGVb9m4R4/5NgmSUN+rotRs=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.120.4"></head><body class="preload-transitions colorscheme-dark"><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Darvein
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/infosec/>Infosec</a></li><li class=navigation-item><a class=navigation-link href=/coding/>Coding</a></li><li class=navigation-item><a class=navigation-link href=/devops/>Devops</a></li></ul></section></nav><div class=content><section class="container page"><article><h1 id=datascience-basis>Datascience basis
<a class=heading-link href=#datascience-basis><i class="fa fa-link" aria-hidden=true></i></a></h1><h2 id=intro>Intro
<a class=heading-link href=#intro><i class="fa fa-link" aria-hidden=true></i></a></h2><p>Data VS Big Data!!! &mdash;> Se trata de las mismas ideas y objetivos aplicadas a 2 situaciones:</p><ul><li>cuando el volumen, la velocidad, la variedad, la veracidad/confiabilidad, y el valor del corpus de datos en uso son manejables dentro de los parámetros básicos en cuanto a infraestructura lógica y técnicas de procesamiento</li><li>cuando el volumen, la velocidad, la variedad, la veracidad/confiabilidad, y el valor del corpus de datos en uso son tales (en un caso o en los cinco) que hacen necesario el despliegue, operaciones y procesamiento en un ecosistema distribuido</li></ul><h2 id=steps>Steps:
<a class=heading-link href=#steps><i class="fa fa-link" aria-hidden=true></i></a></h2><p>En la práctica estos pasos no son lineales e incrementales, sino q pueden ser iterativos o simultáneos &mldr;como puede verse, los pasos 1 y 2 corresponden a lo q normalmente se entiende como Data Engineering, en tanto q los pasos 3 al 6 son más bien lo q corresponde al Data Scientist como tal. Sin embargo es fundamental tener presente el hecho de que, según
<a href=https://www.anaconda.com/state-of-data-science-2020>reporte de Anaconda</a>
, al 2020 las tareas de preparación de datos continúan consumiendo al menos el 45% del tiempo (hasta el doble, en casos extremos) del Data Scientis. Por ello se considera de importancia la comprensión no sólo de DS, sino también de Data Engineering</p><ol><li>Obtaining data</li><li>Cleaning/Scrubbing data</li><li>Exploring data</li><li>Modeling data</li><li>Interpreting data</li><li>Reporting/Communicating data products</li></ol><p><figure class=image-container><a href=.././data_sci_process.jpeg><img width="Data Science Process%" src=.././data_sci_process.jpeg alt="Data Science Process"></a><figcaption>&#8213; Data Science Process &#8213;</figcaption></figure></p><h3 id=data-science-vs-data-engineering>Data Science VS Data Engineering
<a class=heading-link href=#data-science-vs-data-engineering><i class="fa fa-link" aria-hidden=true></i></a></h3><p>Data Science VS Data Engineering &mdash;> Ambos se complementan. Ambos necesitan base en análisis, programación, y Big Data.</p><ul><li>Data Engineer: Mucho más avanzado en programación y software tooling, e infraestructuras distribuidas. Su input es el Raw Data (múltiple, no estructurado, messy) de los diversos Business Systems. Su output serían las Data Pipelines.</li><li>Data Scientist: Mucho más avanzado en recursos/tooling cuantitativos (Matemática, Estadística) y métodos científicos, Machine Learning, y Modeling/Analytics. Su input serían las Data Pipelines. Su output serían los Data Products.</li></ul><h3 id=lógica-del-análisis-cuantitativo-y-algunas-de-las-técnicas-principales>Lógica del Análisis Cuantitativo, y algunas de las técnicas principales
<a class=heading-link href=#l%c3%b3gica-del-an%c3%a1lisis-cuantitativo-y-algunas-de-las-t%c3%a9cnicas-principales><i class="fa fa-link" aria-hidden=true></i></a></h3><ol><li>Descubrir estructura en el corpus de datos (que normalmente es muy grande y sin orden aparente), así como extraer factores clave del mismo. Cómo se ve la data y qué información contiene. Aprendizaje no supervisado: Clustering, Análisis de Componentes Principales PCA.</li><li>Podemos modelizar la data como una relación de función (regresión)? Podemos usar datos continuos para realizar predicciones?. Aprendizaje Supervisado: Regresión Lineal, Inferencia, Regresión No Lineal, Causalidad.</li><li>Podemos modelizar la data como una relación de función (test de hipótesis y clasificación)? Podemos usar datos discretos para realizar predicciones?. Test de Hipótesis, Intervalos de Confianza, Estimación de Probabilidad, Clasificadores SVM y Perceptrones, Regresión Logística.</li></ol></article></section></div><footer class=footer><section class=container>©
2021 -
2024
Dennis Ruiz
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js integrity="sha256-I2BJOV3DaC+ycZZAhylY4S8fJAZ7sJwyeyM+YpDH7aw="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6CQZY8W0WD"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6CQZY8W0WD")</script><script>$(document).on("input propertychange paste change",".FilterSearch",function(){var n=$(this).val().toLowerCase(),s=$(this).closest("ul"),t=s.find("li:gt(0)");t.hide(),t.filter(function(){var e=$(this).text().toLowerCase();return e.indexOf(n)>=0}).show()})</script></body></html>